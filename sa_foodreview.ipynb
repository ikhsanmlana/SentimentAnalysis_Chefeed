{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>AuthorName</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>DateSubmitted</th>\n",
       "      <th>DateModified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>992</td>\n",
       "      <td>2008</td>\n",
       "      <td>gayg msft</td>\n",
       "      <td>5</td>\n",
       "      <td>better than any you can get at a restaurant!</td>\n",
       "      <td>2000-01-25T21:44:00Z</td>\n",
       "      <td>2000-01-25T21:44:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4384</td>\n",
       "      <td>1634</td>\n",
       "      <td>Bill Hilbrich</td>\n",
       "      <td>4</td>\n",
       "      <td>I cut back on the mayo, and made up the differ...</td>\n",
       "      <td>2001-10-17T16:49:59Z</td>\n",
       "      <td>2001-10-17T16:49:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4523</td>\n",
       "      <td>2046</td>\n",
       "      <td>Gay Gilmore ckpt</td>\n",
       "      <td>2</td>\n",
       "      <td>i think i did something wrong because i could ...</td>\n",
       "      <td>2000-02-25T09:00:00Z</td>\n",
       "      <td>2000-02-25T09:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>7435</td>\n",
       "      <td>1773</td>\n",
       "      <td>Malarkey Test</td>\n",
       "      <td>5</td>\n",
       "      <td>easily the best i have ever had.  juicy flavor...</td>\n",
       "      <td>2000-03-13T21:15:00Z</td>\n",
       "      <td>2000-03-13T21:15:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>2085</td>\n",
       "      <td>Tony Small</td>\n",
       "      <td>5</td>\n",
       "      <td>An excellent dish.</td>\n",
       "      <td>2000-03-28T12:51:00Z</td>\n",
       "      <td>2000-03-28T12:51:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewId  RecipeId  AuthorId        AuthorName  Rating  \\\n",
       "0         2       992      2008         gayg msft       5   \n",
       "1         7      4384      1634     Bill Hilbrich       4   \n",
       "2         9      4523      2046  Gay Gilmore ckpt       2   \n",
       "3        13      7435      1773     Malarkey Test       5   \n",
       "4        14        44      2085        Tony Small       5   \n",
       "\n",
       "                                              Review         DateSubmitted  \\\n",
       "0       better than any you can get at a restaurant!  2000-01-25T21:44:00Z   \n",
       "1  I cut back on the mayo, and made up the differ...  2001-10-17T16:49:59Z   \n",
       "2  i think i did something wrong because i could ...  2000-02-25T09:00:00Z   \n",
       "3  easily the best i have ever had.  juicy flavor...  2000-03-13T21:15:00Z   \n",
       "4                                 An excellent dish.  2000-03-28T12:51:00Z   \n",
       "\n",
       "           DateModified  \n",
       "0  2000-01-25T21:44:00Z  \n",
       "1  2001-10-17T16:49:59Z  \n",
       "2  2000-02-25T09:00:00Z  \n",
       "3  2000-03-13T21:15:00Z  \n",
       "4  2000-03-28T12:51:00Z  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReviewId           0\n",
       "RecipeId           0\n",
       "AuthorId           0\n",
       "AuthorName         0\n",
       "Rating             0\n",
       "Review           214\n",
       "DateSubmitted      0\n",
       "DateModified       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReviewId         0\n",
       "RecipeId         0\n",
       "AuthorId         0\n",
       "AuthorName       0\n",
       "Rating           0\n",
       "Review           0\n",
       "DateSubmitted    0\n",
       "DateModified     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Review'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviews'] = df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         better than any you can get at a restaurant!\n",
       "1    i cut back on the mayo, and made up the differ...\n",
       "2    i think i did something wrong because i could ...\n",
       "3    easily the best i have ever had.  juicy flavor...\n",
       "4                                   an excellent dish.\n",
       "Name: cleaned_reviews, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1798854/3349767945.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_reviews'] = df['cleaned_reviews'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          better than any you can get at a restaurant\n",
       "1    i cut back on the mayo and made up the differe...\n",
       "2    i think i did something wrong because i could ...\n",
       "3    easily the best i have ever had  juicy flavorf...\n",
       "4                                    an excellent dish\n",
       "Name: cleaned_reviews, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'] = df['cleaned_reviews'].str.replace('[^\\w\\s]','') \n",
    "df['cleaned_reviews'].head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(text):\n",
    "    filtered_words = []\n",
    "    for x in text: \n",
    "        if x not in stop_words:\n",
    "            filtered_words.append(x)\n",
    "    \n",
    "    return filtered_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: x.split(\" \"))\n",
    "df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: remove_sw(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            [better, get, restaurant]\n",
       "1    [cut, back, mayo, made, difference, sour, crea...\n",
       "2    [think, something, wrong, could, taste, cornst...\n",
       "3    [easily, best, ever, , juicy, flavorful, dry, ...\n",
       "4                                    [excellent, dish]\n",
       "Name: cleaned_reviews, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[better, get, restaurant]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cut, back, mayo, made, difference, sour, crea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[think, something, wrong, could, taste, cornst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[easily, best, ever, , juicy, flavorful, dry, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[excellent, dish]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401977</th>\n",
       "      <td>[disappointed, couldnt, wait, make, husband, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401978</th>\n",
       "      <td>[nothing, drain, dont, heat, liquids, put, mil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401979</th>\n",
       "      <td>[good, base, recipe, someone, start, quadruple...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401980</th>\n",
       "      <td>[thank, much, amazing, recipe, lived, kenai, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401981</th>\n",
       "      <td>[cant, say, enough, recipe, best, pot, roast, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1401768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_reviews  is_positive\n",
       "0                                [better, get, restaurant]            1\n",
       "1        [cut, back, mayo, made, difference, sour, crea...            1\n",
       "2        [think, something, wrong, could, taste, cornst...            0\n",
       "3        [easily, best, ever, , juicy, flavorful, dry, ...            1\n",
       "4                                        [excellent, dish]            1\n",
       "...                                                    ...          ...\n",
       "1401977  [disappointed, couldnt, wait, make, husband, b...            0\n",
       "1401978  [nothing, drain, dont, heat, liquids, put, mil...            1\n",
       "1401979  [good, base, recipe, someone, start, quadruple...            1\n",
       "1401980  [thank, much, amazing, recipe, lived, kenai, s...            1\n",
       "1401981  [cant, say, enough, recipe, best, pot, roast, ...            1\n",
       "\n",
       "[1401768 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "df['is_positive'] = np.where(df['Rating']<3, 0, 1) \n",
    "\n",
    "df[['cleaned_reviews','is_positive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'] = df['cleaned_reviews'].apply(lambda x: list(filter(None,x)))\n",
    "        \n",
    "\n",
    "max_word = max(df.cleaned_reviews, key=len) \n",
    "len(max_word)\n",
    "\n",
    "# import urllib.request \n",
    "\n",
    "# url = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
    "# filename = 'glove.6b.zip'\n",
    "# urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.cleaned_reviews.str.len() < 100]\n",
    "\n",
    "max_word = max(df.cleaned_reviews, key=len) \n",
    "len(max_word)\n",
    "\n",
    "# import zipfile \n",
    "\n",
    "# with zipfile.ZipFile('glove.6b.zip', 'r') as zip: \n",
    "#     zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = dict()\n",
    "\n",
    "def add_wordvector(dict, filename):\n",
    "    with open(filename, 'r', encoding='utf8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(' ')\n",
    "\n",
    "            try:\n",
    "                if line[0] not in stop_words:\n",
    "                    dict[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue \n",
    "\n",
    "\n",
    "add_wordvector(word_vectors, 'glove.6B.50d.txt')\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399851"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['better', 'get', 'restaurant']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_token(text):\n",
    "    lemmatized_token = [lemmatizer.lemmatize(x) for x in text] \n",
    "    useful_token = [x for x in lemmatized_token if x in word_vectors]\n",
    "\n",
    "    return useful_token \n",
    "\n",
    "word_token = df['cleaned_reviews'][0] \n",
    "\n",
    "lemmatize_token(word_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text, token_dict=word_vectors):\n",
    "    processed_token = lemmatize_token(text)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    for x in processed_token:\n",
    "        if x not in word_vectors:\n",
    "            continue \n",
    "        \n",
    "        vectors.append(token_dict[x]) \n",
    "\n",
    "    return np.array(vectors, dtype=float) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_review(df):\n",
    "    label = df['is_positive'].to_numpy().astype(int)\n",
    "\n",
    "    len_wordvector = []\n",
    "\n",
    "    for text in df['cleaned_reviews']:\n",
    "        text_as_vector = text_to_vector(text) \n",
    "\n",
    "        if text_as_vector.shape[0] == 0:\n",
    "            text_as_vector = np.zeros(shape=(1,50)) \n",
    "\n",
    "        len_wordvector.append(text_as_vector)\n",
    "\n",
    "    return len_wordvector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350481, 75103, 75104)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.sample(frac=.36, random_state=1)\n",
    "train_df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "split_index_1 = int(len(train_df) * 0.7)\n",
    "split_index_2 = int(len(train_df) * 0.85)\n",
    "\n",
    "train_df, val_df, test_df = train_df[:split_index_1], train_df[split_index_1:split_index_2], train_df[split_index_2:]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350481, 18, 14)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = vectorize_review(train_df) \n",
    "\n",
    "len(x_train), len(x_train[0]), len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    350481.000000\n",
       "mean         25.146704\n",
       "std          16.205611\n",
       "min           1.000000\n",
       "25%          13.000000\n",
       "50%          22.000000\n",
       "75%          33.000000\n",
       "max          99.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_len = []\n",
    "\n",
    "for i in range (len(x_train)):\n",
    "    token_len.append(len(x_train[i])) \n",
    "\n",
    "pd.Series(token_len).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy \n",
    "\n",
    "# def zero_padding(x, max_token_len=605):\n",
    "#     x_copy = deepcopy(x)\n",
    "\n",
    "#     for i, j in enumerate(x):\n",
    "#         x_token_len = j.shape[0]\n",
    "#         token_len_diff = max_token_len - x_token_len \n",
    "\n",
    "#         pad = np.zeros(shape=(token_len_diff, 50))\n",
    "\n",
    "#         x_copy[i] = np.concatenate([j, pad]) \n",
    "\n",
    "#     return np.array(x_copy).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = zero_padding(x_train)\n",
    "\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350481, 100, 50)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.keras.utils.pad_sequences(x_train, maxlen=100, dtype='float32', padding='post') \n",
    "\n",
    "x_train.shape\n",
    "\n",
    "\n",
    "# tf.keras.utils.pad_sequences([[1, 2, 3], [3, 4, 5, 6], [7, 8]], dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350481,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75103, 100, 50), (75103,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = vectorize_review(val_df)\n",
    "x_val = tf.keras.utils.pad_sequences(x_val, maxlen=100, dtype='float32', padding='post')\n",
    "\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75104, 100, 50), (75104,))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = vectorize_review(test_df)\n",
    "x_test = tf.keras.utils.pad_sequences(x_test, maxlen=100, dtype='float32', padding='post')\n",
    "\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "model = Sequential([])\n",
    "\n",
    "model.add(layers.Input(shape=(100,50))) \n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.LSTM(64, return_sequences=True))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.LSTM(64, return_sequences=True))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 64)           29440     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6401      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,841\n",
      "Trainable params: 35,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.metrics import AUC \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "model_cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=BinaryCrossentropy(), metrics=['accuracy', AUC(name='auc')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    322925\n",
       "0     27556\n",
       "Name: is_positive, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq = pd.value_counts(train_df['is_positive']) \n",
    "class_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.359431702714472, 1: 0.5426662537740962}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {0: class_freq.sum() / (class_freq[0] * 2), 1: class_freq.sum() / (class_freq[1] * 2)} \n",
    "\n",
    "weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10951/10953 [============================>.] - ETA: 0s - loss: 0.5710 - accuracy: 0.7230 - auc: 0.7698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10953/10953 [==============================] - 78s 7ms/step - loss: 0.5711 - accuracy: 0.7230 - auc: 0.7699 - val_loss: 0.5644 - val_accuracy: 0.7217 - val_auc: 0.7991\n",
      "Epoch 2/5\n",
      "10953/10953 [==============================] - 75s 7ms/step - loss: 0.5366 - accuracy: 0.7593 - auc: 0.8023 - val_loss: 0.5797 - val_accuracy: 0.7276 - val_auc: 0.8076\n",
      "Epoch 3/5\n",
      "10949/10953 [============================>.] - ETA: 0s - loss: 0.5229 - accuracy: 0.7748 - auc: 0.8137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10953/10953 [==============================] - 76s 7ms/step - loss: 0.5230 - accuracy: 0.7748 - auc: 0.8136 - val_loss: 0.5334 - val_accuracy: 0.7619 - val_auc: 0.8167\n",
      "Epoch 4/5\n",
      "10952/10953 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.7832 - auc: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10953/10953 [==============================] - 76s 7ms/step - loss: 0.5139 - accuracy: 0.7832 - auc: 0.8210 - val_loss: 0.4768 - val_accuracy: 0.8047 - val_auc: 0.8208\n",
      "Epoch 5/5\n",
      "10953/10953 [==============================] - 75s 7ms/step - loss: 0.5080 - accuracy: 0.7897 - auc: 0.8257 - val_loss: 0.5138 - val_accuracy: 0.7688 - val_auc: 0.8228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f43cefee0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val,y_val), epochs=5, callbacks=[model_cp], class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
